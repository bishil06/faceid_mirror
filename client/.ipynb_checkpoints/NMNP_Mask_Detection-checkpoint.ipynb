{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.3.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25856 sha256=a6c0e2414a9b2e069995f3e24fcd0618cb51152338adc87f6220f6f349904da4\n",
      "  Stored in directory: c:\\users\\cho\\appdata\\local\\pip\\cache\\wheels\\c8\\d6\\0f\\b0c3892b70c59f0d202f8619a449f7d14cb839a0af2f943869\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images with facemask labelled 'yes': 27784\n",
      "The number of images with facemask labelled 'no': 30000\n"
     ]
    }
   ],
   "source": [
    "#수집한 데이터셋 수량 비교 (Yes = 착용, No = 미착용)\n",
    "print(\"The number of images with facemask labelled 'yes':\",len(os.listdir('../Mask/YES')))\n",
    "print(\"The number of images with facemask labelled 'no':\",len(os.listdir('../Mask/NO')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 (폴더 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 폴더별로 분배\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    dataset = []\n",
    "    \n",
    "    for unitData in os.listdir(SOURCE):\n",
    "        data = SOURCE + unitData\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(unitData)\n",
    "        else:\n",
    "            print('Skipped ' + unitData)\n",
    "            print('Invalid file i.e zero size')\n",
    "    \n",
    "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
    "    test_set_length = int(len(dataset) - train_set_length)\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    train_set = dataset[0:train_set_length]\n",
    "    test_set = dataset[-test_set_length:]\n",
    "       \n",
    "    for unitData in train_set:\n",
    "        temp_train_set = SOURCE + unitData\n",
    "        final_train_set = TRAINING + unitData\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "    for unitData in test_set:\n",
    "        temp_test_set = SOURCE + unitData\n",
    "        final_test_set = TESTING + unitData\n",
    "        copyfile(temp_test_set, final_test_set)\n",
    "        \n",
    "        \n",
    "YES_SOURCE_DIR = \"../Mask/YES/\"\n",
    "TRAINING_YES_DIR = \"../Mask/trial/training/yes1/\"\n",
    "VALIDATING_YES_DIR = \"../Mask/trial/validating/yes1/\"\n",
    "TESTING_YES_DIR = \"../Mask/trial/testing/yes1/\"\n",
    "NO_SOURCE_DIR = \"../Mask/NO/\"\n",
    "TRAINING_NO_DIR = \"../Mask/trial/training/no1/\"\n",
    "VALIDATING_NO_DIR = \"../Mask/trial/validating/no1/\"\n",
    "TESTING_NO_DIR = \"../Mask/trial/testing/no1/\"\n",
    "\n",
    "#훈련셋과 테스트셋 분배\n",
    "split_size = .9\n",
    "split_data(YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size)\n",
    "split_data(NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size)\n",
    "\n",
    "#검증셋 분배는 코드화 필요...지금은 그냥 손으로 옮김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images with facemask in the training set labelled 'yes': 20005\n",
      "The number of images with facemask in the validate set labelled 'yes': 5000\n",
      "The number of images with facemask in the test set labelled 'yes': 2779\n",
      "The number of images without facemask in the training set labelled 'no': 21600\n",
      "The number of images with facemask in the validate set labelled 'no': 5400\n",
      "The number of images without facemask in the test set labelled 'no': 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of images with facemask in the training set labelled 'yes':\", len(os.listdir('../Mask/trial/training/yes1/')))\n",
    "print(\"The number of images with facemask in the validate set labelled 'yes':\", len(os.listdir('../Mask/trial/validating/yes1/')))\n",
    "print(\"The number of images with facemask in the test set labelled 'yes':\", len(os.listdir('../Mask/trial/testing/yes1/')))\n",
    "\n",
    "print(\"The number of images without facemask in the training set labelled 'no':\", len(os.listdir('../Mask/trial/training/no1/')))\n",
    "print(\"The number of images with facemask in the validate set labelled 'no':\", len(os.listdir('../Mask/trial/validating/no1/')))\n",
    "print(\"The number of images without facemask in the test set labelled 'no':\", len(os.listdir('../Mask/trial/testing/no1/')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의 & 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model 정의\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (5,5), activation='relu', input_shape=(112, 112, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),    \n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model to disk\n"
     ]
    }
   ],
   "source": [
    "#학습이 완료된 모델을 불러올 수 있음\n",
    "#위의 모델정의 후에 이 코드 실행해야 불러와짐\n",
    "#model.load_weights(\"model_weight.h5\")\n",
    "#print(\"load model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41605 images belonging to 2 classes.\n",
      "Found 10400 images belonging to 2 classes.\n",
      "Found 832 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "###훈련을 진행할 경우에만 실행###\n",
    "TRAINING_DIR = \"../Mask/trial/training\"\n",
    "#이미지에 적절한 변형을 주어 훈련(다양성)\n",
    "train = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_set = train.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=200, \n",
    "                                                    target_size=(112, 112))\n",
    "VALIDATION_DIR = \"../Mask/trial/validating\"\n",
    "validation = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_set = validation.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=200, \n",
    "                                                         target_size=(112, 112))\n",
    "TEST_DIR = \"../Mask/trial/testing\"\n",
    "test = ImageDataGenerator(rescale=1.0/255)\n",
    "test_set = test.flow_from_directory(TEST_DIR, batch_size=10, target_size=(112, 112))\n",
    "\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###훈련을 진행할 경우에만 실행###\n",
    "#모델 학습 batch_size는 gererator에서 수정\n",
    "history = model.fit(train_set,\n",
    "                              epochs=10,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습이 끝난 모델을 저장\n",
    "#model.save_weights(\"model_weight.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyV1bnw/d+VmUwkZCIkQBjCLDJEnBBRnAesFi22tmq1VFtrbXvOqfV9TrWnT59jW9ujfd+qD23tqUcrIMoRWxU8ForUVkmYZIqEMQEyMmSedq73j/tOsgmB7MAmeyf7+n4++5O972mve2fvda17rXWvJaqKMcaY0BMW6AQYY4wJDAsAxhgToiwAGGNMiLIAYIwxIcoCgDHGhKiIQCegN1JTUzUnJyfQyTDGmH6loKCgUlXTui7vVwEgJyeH/Pz8QCfDGGP6FRE50N1yqwIyxpgQZQHAGGNClAUAY4wJUf2qDaA7LS0tlJSU0NjYGOikDAgxMTFkZ2cTGRkZ6KQYY86zfh8ASkpKSEhIICcnBxEJdHL6NVWlqqqKkpISRo0aFejkGGPOsx6rgETkJREpF5Ftp1kvIvIrESkSka0iMsNr3Q0iUuiue9xr+RAReV9Edrt/k8/2BBobG0lJSbHM3w9EhJSUFLuaMiZE+NIG8J/ADWdYfyOQ6z4WAS8AiEg48Gt3/STgbhGZ5O7zOPCBquYCH7ivz5pl/v5jn6UxoaPHKiBVXSciOWfY5DbgZXXGlf6HiCSJSCaQAxSp6l4AEVnibrvD/TvX3f8PwFrg+2d1BsYYc648rVBf5T4qnb91ldB4HIZOhdFzISI60Kn0O3+0AWQBxV6vS9xl3S2/2H2eoapHAFT1iIikn+7gIrII58qCESNG+CG5/nX8+HH++Mc/8o1vfKNX+91000388Y9/JCkp6bTb/PCHP2TOnDlcc80155pMY05PFWrL4fgBOHYAmmshKh6i4yEqznke5T6PjofIOAgP4uZDVWipdzLw+kqoP+o+dzP3OndZx/MqJ6M/k6gEGHc9TJoPY69xPosBwB//xe7qDPQMy3tFVRcDiwHy8vKCbvaa48eP8/zzz58SADweD+Hh4afd75133unx2P/2b/92zukzBoCG450Z/Cl/D0JrQ++OFzHIDQ5xEJ3Q+bw9WHQEjzgn8zxlW6/gEh0PkbFwuurHtjZoOHZq6fykzL19ubtN62nascIiIDYVYlMgLgUypzqv49xlsSlez1OdtB34CHa8Bbv+DNuWO+c+dh5Mus0JCjGDe/fZBRF/BIASYLjX62zgMBB1muUAZSKS6Zb+M4FyP6QjIB5//HH27NnDtGnTiIyMJD4+nszMTDZv3syOHTv43Oc+R3FxMY2NjXz7299m0aJFQOewFrW1tdx4443Mnj2bjz76iKysLN566y0GDRrEfffdxy233MKCBQvIycnh3nvv5e2336alpYXXX3+dCRMmUFFRwRe/+EWqqqq46KKLeO+99ygoKCA1NTXAn4zpUy0NTkbekbHvPzmjbzxx8vbRgyF5BKTmQu61kDQSkkc6f6MTnBJ0cy001UJznfO82X3e5PW8Y1kNNFZD9ZHObZtqoa3FxxOQLoEhDlqbnEy94ShoW/e7RcV3ZtrxGZA+GWKHuJl4apcMPcXJrHvbzpV7rfO45Vk4+BHsfNt57PoThEU61UMTb4UJNzvv1Y/4IwCsBB5x6/gvBk64GXsFkCsio4BDwELgi1773As87f59yw/p4Edvb2fH4Wp/HKrDpGGJPHnr5NOuf/rpp9m2bRubN29m7dq13HzzzWzbtq2jG+VLL73EkCFDaGho4KKLLuLzn/88KSkpJx1j9+7dvPbaa/zmN7/hrrvu4o033uCee+455b1SU1PZuHEjzz//PM888wy//e1v+dGPfsTVV1/ND37wA9577z0WL17s1/M3QcLTCtWHTlOK3w+1ZSdvHx7dmaEPn3VyBp88Egaddce73mltPjl4tAeLboNK3cnBIyKqS+k81Sm1tz+PTYHImL45D3CqvUbNcR43/BQO5cPOlbBjJbz9KPzpMRh5OUycDxNvgcRhfZe2s9RjABCR13AabFNFpAR4EogEUNUXgXeAm4AioB64313XKiKPAKuAcOAlVd3uHvZpYJmIPAAcBO704zkF1KxZs07qQ/+rX/2KFStWAFBcXMzuzz4j5dJLT9pn1KhRTJs2DYCZM2eyf//+bo99xx13dGzz5ptvArB+/fqO499www0kJ/fRD9sfPK3BXZfcl1ShrsLJzI8dgOP7T87oT5SAejq3lzBIzHYy87HXnpy5J410SsNhQXCjf0QURAxxSuUDSViYE1iHz4JrfwylnzrBYOfb8O4/O4/si9xgcCsMCc77anzpBXR3D+sV+OZp1r2DEyC6Lq8C5vmYRp+dqaTeV+LiOhuH1q5dy//8z/v8/S/vEBvWwtyb76Tx8HaoTIU2j1Mv2+ohOrqzd0F4eDgNDd3Xx7ZvFx4eTmtrK+DcvNUvtDZB2TY4tNF9FEDlZzB0ivsjmQ/pEwKdyr6lCoc3dWYcVUUnr49LdzL07IvgggUnZ/CDsyHc7tYOCiJOW0LmVLj6f0HFZ+7/dCW8/6/OY+gFQfk9t+LXOUpISKCmpubkhZ5maDzBieJdJA+KILapnF1FB/nHxq0QnejUZ6oHThyEuganwapqD0TFQkuj0+jlo9mzZ7Ns2TK+//3vs3r1ao4dO+bnMzwLbW1Qtbszoz9U4GT+nmZnfVwaZM10GtCKP4Y1P3EeqeOc0tLE+ZB5Ye/ravuDNo9zzu31yCeKQcJh1BWQ91VIGetk8EkjnO+D6X/SxkHaP8Gcf3Ku3tr/12v+T9B9zy0AnKOUlBQuv/xypkyexKDoKDJSk6DMqem64cqLefHlpUy9/suMnzCRSy65FOLTIW08hEfBkLEQVuFkAJ5mqKmGhiqoq3eO0VTrdE9rqj3t+z/55JPcfffdLF26lCuvvJLMzEwSEhL66vSdUmz14c6M/vBGOLwZmty2mKh4GDYdLnkYhs1wMv7B2Sd/6auPOA1qO9+G9c/Ch79wMsD2y+fsWcFRnXG2PC2w/0M3I/gT1JU7dfRjroa5P4DxNw68KhLjSB4Jlz3iPGpKO4NBkHzPpd9UIeB0A+06IczOnTuZOHFi3ydG25yMuana6WHRXrqNjIOYRIhJcm4c6U10b/M4vS9a6qHZ/dt+XICIGKd3RGSs+4ihqbmF8PBwIiIi+Pvf/87DDz/M5s2bz+nUzviZNhxzSvaHvapy2hsgwyKdKp2smZ2ZfWouhJ2+O+wp6qqg8B3nR7J3jXP+8UOdRrWJt8LI2f2j3aCl0Un/jpXO+TQed74budc65zHueqe3jQlNdVXw2bvO96Pje54BE25x7jXw8/dcRApUNa/r8n7wSwoiba1OV7fGaifjVw8gzg85PsPpYnYu9bJh4c6xvDMGT4tXQKhz2g3qq9yVwsHicu762ndpU4iKjuY3/uwF1NLgNG61l+4PFcDRvZ3rU8fB6KucjD5rJmRMPvdeGXEpMOPLzqPxBOx+3+mDvfmPsOG3Tu+V8Tc7P5LRc4Pr7symWti92gleu1c7vVmiBzsl/EnznRJ/5KBAp9IEg7gUmH6P82isdr4vO96CLa9B/u/67HtuVwA9aW1yM/0Tzg8adW4miUl0ftzRCb0r4Z4rVae00FzndbXQALjtBhLu1B1HxjolzqhY34KSqtMW0VzHzl2FTNzwOJTvcIIeQMIwyHJL9VkznGqdvrwBprke9nzglJg+e88JwO13Z0681SlZB+LuzIZjUPiek+nv+cD5DGNTnT7hk+ZDzhynJ4wxvmj/nu982/leNZ3o/J7P/o5zhX0W7ArAV6pOybfxhPNov0MyIhri05xMPyoucA03Ik5aIqKBIZ1pbm3orDZqrocmr37hYZFuUHADQuSgzuqm9iuLlobOm21a6p0+1pd/u7M6JzGzz0/1JFGxbsPZrU7f8n1/dXpZdNydGePcoj9xvvNjGXT6ITbOWW2F22axEvatc4JkYhbMvM9J34hL+7ZQYAaOU77n62Cnexfypb0bbsYXdgUAnfX57Zl++92LUXFOKTd6cN/ecOIPbR4nU/fO5L3bEzqIc7XQcdUQy87de5k4aVI32wYhT+vJd2fWHHHvzrzSCQb+ujvzRInTgLtzJRz8u/OdSR7llPInzneCZH9uqDbBzdPqFCrOsuBpVwBdeVo7G3Cbqp0ftIQ5VTrtmX5/aGw8nbBwZxyT6PjOZZ7WzmqjsIiOhmSkS8bVn7pfnnJ3ZoFTYjrl7sxbnQa2wVm+H7tqT2cf/UMFzrK0iTDnn51MP2Ny//qsTP91nvKifpzDnYXWps5SfrPbtTIs0mlwiRns1LUN5FJceASEJzrtFwNRWBgMv8h5nHJ35r84j6y8zlJ717szVaF8Z+ft/eXujevDpsO8Hzr7pOb2/XkZc56ERgCoq3Rus28fITAiprPXzplGITwP4uPjqa2t5fDhwzz66KMsX778lG3mzp3LM888Q17eKVdsHZ599lkWLVpEbKxzs5Avw0uHlDPenflD55FxgRMMsvOcutYdK+HoHkBgxCVw/b873U+Tgm8YcmP8ITQCQJvHqfJIzHIy/SDoOjhs2LBuM39fPfvss9xzzz0dAcCX4aVDWrd3Z6507syEzrtxL/2mU1WUkBHY9BrTBwZwfYeXhAzn0j0+3e+Z//e//32ef/75jtdPPfUUP/rRj5g3bx4zZszgggsu4K23Th3sdP/+/UyZ4nTpamhoYOHChUydOpUvfOELJ40F9PDDD5OXl8fkyZN58sknAWeAucOHD3PVVVdx1VVXAc7w0pWVlQD88pe/ZMqUKUyZMoVnn3224/0mTpzI1772NSZPnsx111132jGHBrz2uzMfWA3f3QV3L4V/LoKvvAUXPWCZvwkZA+sK4N3HnXpffxp6Adz49GlXL1y4kMcee6xjQphly5bx3nvv8Z3vfIfExEQqKyu55JJLmD9//mnn233hhReIjY1l69atbN26lRkzZnSs+8lPfsKQIUPweDzMmzePrVu38uijj/LLX/6SNWvWnDLuf0FBAb///e/5+OOPUVUuvvhirrzySpKTk30edjqkJGYGvourMQESGlcA59H06dMpLy/n8OHDbNmyheTkZDIzM3niiSeYOnUq11xzDYcOHaKsrOy0x1i3bl1HRjx16lSmTp3asW7ZsmXMmDGD6dOns337dnbs2HHG9Kxfv57bb7+duLg44uPjueOOO/jwww8B34edNsaEhoF1BXCGkvr5tGDBApYvX05paSkLFy7k1VdfpaKigoKCAiIjI8nJyaGx8TRT1Lm6uzrYt28fzzzzDBs2bCA5OZn77ruvx+Oc6b4OX4edNsaEBrsC8IOFCxeyZMkSli9fzoIFCzhx4gTp6elERkayZs0aDhw4cMb958yZw6uvvgrAtm3b2Lp1KwDV1dXExcUxePBgysrKePfddzv26XYYavdY//3f/019fT11dXWsWLGCK664wo9na4wZKAbWFUCATJ48mZqaGrKyssjMzORLX/oSt956K3l5eUybNo0JE848AcTDDz/M/fffz9SpU5k2bRqzZs0C4MILL2T69OlMnjyZ0aNHc/nll3fss2jRIm688UYyMzNZs2ZNx/IZM2Zw3333dRzjwQcfZPr06VbdY4w5hQ0FYU5hn6kxA8vphoKwKiBjjAlRPgUAEblBRApFpEhEHu9mfbKIrBCRrSLyiYhM8Vr3bRHZJiLbReQxr+VPicghEdnsPm7yzykZY4zxRY8BQETCgV8DNwKTgLtFpOtQkU8Am1V1KvAV4Dl33ynA14BZwIXALSLiPZjKf6jqNPdx1rey9qdqrGBnn6UxocOXK4BZQJGq7lXVZmAJcFuXbSYBHwCo6i4gR0QygInAP1S1XlVbgb8Ct/st9UBMTAxVVVWWcfmBqlJVVUVMTD8b+toYc1Z86QWUBRR7vS4BLu6yzRbgDmC9iMwCRgLZwDbgJyKSAjQANwHerbiPiMhX3GXfU9VjvT2B7OxsSkpKqKio6O2uphsxMTFkZ2cHOhnGmD7gSwDobvyCrsXtp4HnRGQz8CmwCWhV1Z0i8lPgfaAWJ1C4cwzyAvBj91g/Bn4BfPWUNxdZBCwCGDHi1FEZIyMjGTVq1CnLjTHGnJkvVUAlwHCv19nAYe8NVLVaVe9X1Wk4bQBpwD533e9UdYaqzgGOArvd5WWq6lHVNuA3OFVNp1DVxaqap6p5aWlpvTw9Y4wxp+NLANgA5IrIKBGJAhYCK703EJEkdx3Ag8A6Va1216W7f0fgVBO95r72HoHrdpzqImOMMX2kxyogVW0VkUeAVUA48JKqbheRh9z1L+I09r4sIh5gB/CA1yHecNsAWoBvetXz/0xEpuFUAe0Hvu6nczLGGOODfn8nsDHGmDOzO4GNMcacxAKAMcaEKAsAxhgToiwAGGNMiLIAYIwxIcoCgDHGhCgLAMYYE6IsABhjTIiyAGCMMSHKAoAxxoQoCwDGGBOiLAAYY0yIsgBgjDEhygKAMcaEKAsAxhgToiwAGGNMiLIAYIwxIcoCgDHGhCgLAMYYE6IsABhjTIjyKQCIyA0iUigiRSLyeDfrk0VkhYhsFZFPRGSK17pvi8g2EdkuIo95LR8iIu+LyG73b7J/TskYY4wvegwAIhIO/Bq4EZgE3C0ik7ps9gSwWVWnAl8BnnP3nQJ8DZgFXAjcIiK57j6PAx+oai7wgfvaGGNMH/HlCmAWUKSqe1W1GVgC3NZlm0k4mTiqugvIEZEMYCLwD1WtV9VW4K/A7e4+twF/cJ//AfjcOZ2JMcaYXvElAGQBxV6vS9xl3rYAdwCIyCxgJJANbAPmiEiKiMQCNwHD3X0yVPUIgPs3vbs3F5FFIpIvIvkVFRW+nZUxxpge+RIApJtl2uX100CyiGwGvgVsAlpVdSfwU+B94D2cQNHamwSq6mJVzVPVvLS0tN7saowx5gwifNimhM5SOzgl+8PeG6hqNXA/gIgIsM99oKq/A37nrvs/7vEAykQkU1WPiEgmUH4O52GMMaaXfLkC2ADkisgoEYkCFgIrvTcQkSR3HcCDwDo3KCAi6e7fETjVRK+5260E7nWf3wu8dS4nYowxpnd6vAJQ1VYReQRYBYQDL6nqdhF5yF3/Ik5j78si4gF2AA94HeINEUkBWoBvquoxd/nTwDIReQA4CNzpr5MyxphzdaKhhY0HjzF4UCTjMxKIi/alwqR/EdWu1fnBKy8vT/Pz8wOdDGPMANTiaWNz8XE+3F3J+t0VbCk5gaetM38cMSSW8UMTmDg0gfFDE5mQmUBOShzhYd01kwYXESlQ1byuywdeSDPGGB+oKnsq6li/u4L1RZX8Y+9RaptaCROYmp3EN+aO4dLRKdQ2tVJYWsOu0hp2lVbzwc4y2uNCdEQY4zISGD80gQlDE5gwNJHxQxNIS4gO7Mn5yAKAMSZkVNU28bc9VU6mv7uSwycaAad0f9u0YVyRm8qlo1MZHBt50n7XTR7a8byxxUNReS07j1RTWFpDYVkNawsrWF5Q0rFNanyUGxQSO4LDuIwEYiLD++ZEfWQBwBgzYDW2eCg4cIx1boa//XA1AIkxEVw+NpVvXp3KFWPTGJES6/MxYyLDmZI1mClZg09aXlnb1HmlcKSawrIaXv34AI0tbQCECeSkxDEhM4HxGU4V0oShCQxPjiUsQNVIFgCMMQOGqrLzSA3riyr4cHcln+w7SlNrG5HhwvQRyXzv2nFcMS6NC7IG+73uPjU+mtSx0Vw+NrVjmadNOVBVR2FpDTtLaygsrWbH4Wre3VZKe/NrbFQ44zLaq5Dc9oWhCSTHRZ3mnfzHGoGNMf1a6YlG1hdV8uHuCv5WVEllbTMAuenxzM5N5YrcVC4elRJUvXjqm1v5rKyWXUeqO9oWCktrOFbf0rFNRmI044cmuo3OCczOTSU9Ieas3s8agY0xA0JdUysf76tye+tUsru8FnDq3S8fm8rssalckZvG0MFnl1n2hdioCKYNT2La8KSOZapKRU1Tx5XCriNOddLv91TR7GnjD1+dddYB4HQsABhjgpqnTfn00AnW73aqdTYePEaLR4mOCGPWqCHcmZfN7LFpTBiaELC6dH8QEdITY0hPjOHKcZ3D3rR42thfWcewpEF+f08LAMaYoNLiaeNAVR0f7zvK+t2VfLSnihMNTtXI5GGJfHX2KObkpjFzZHLQ9ao5HyLDw8jNSDgvx7YAYIwJiMYWD3sqaikqP/mxv6qOFo/TNjlscAzXT85gdm4al49JISW+f/Sv7y8sABhjzqsTDS0Uldeyp7yWoopadpfVUFRRS8mxho6eMOFhwsghsYxJj+faSRmMTY9nanYSY9LicMaXNOeDBQBjzDlTVSpqmzoy+t1eJfrymqaO7aIiwhidGse04cksmDGcsenx5GbEMzIlluiIgV+dE2wsABhjfNbWphw63nBytY1bqq9u7JzqIz46grHp8cwZl+Zk8unxjE2PJzs5tl+MnRMqLAAYY07R3hDrndHvLq9lb0UdDS2eju1S46MYkxbPrRcOczP5BMamx5ORGG1VN/2ABQBjQoinTTla10xlbRNVtc5f59H5vORYA/sr62j1GgkzK2kQY9LjuWR0CmPd0vzYtPg+uVvVnD8WAIzp55paPd1n5jVuRl/X+fxofTPd3fwfGS7OUAbx0YxOjeM6tyE2Nz2B0WlxQXUXrfEf+68aE2RUlbpmD5U1TuZdUdOZuXtn9FW1zVTUNlHT2P0023FR4aTER5MaH8XIlFhmjEwmLT6K1AQno0+J63yeGBNhVTYhyAKAMX2krU05Vt9MWXUTZTWNVFQ3UVbdSFlNI2XVTZTXNHVk+u0jSHaVFBvpZNzx0UwclsgV7vOOTD0+ijT3b2yU/bzNmdk3xJhzpKocr2+hrKaRcjdTL69xM/dqJ3OvqGmivKax4wYnb0mxkWQkxJCe6FS/eJfMU+OjOqpmhsRFERXhyzTexvjGAoAxp6GqVDe0npSxd5fJl1c30ew5tcSeGBNBRmIMGYkxjE6LIyMxhvSEaHdZNOkJMaQlRIfEcAYmOPkUAETkBuA5nEnhf6uqT3dZnwy8BIwBGoGvquo2d913gAcBBT4F7lfVRhF5CvgaUOEe5glVfeecz8iYXiivbuTve6s4cqKxI1Mvd0vtZdWNNLWemrEnxER0ZOQX5Qwh3c3MMxLdzN0tzVvGboJdjwFARMKBXwPXAiXABhFZqao7vDZ7AtisqreLyAR3+3kikgU8CkxS1QYRWQYsBP7T3e8/VPUZ/52OMT3bW1HL6h1lrNpeyqaDxzuWx0c7GXt6YjTTRyR1lNjTE2PIcDP89MRoq1s3A4Yv3+RZQJGq7gUQkSXAbYB3AJgE/DuAqu4SkRwRyfB6j0Ei0gLEAof9lXhjfKHqDCe8anspq7eXdYwff0HWYL537TiunpjOyJQ44q2rowkxvnzjs4Bir9clwMVdttkC3AGsF5FZwEggW1ULROQZ4CDQAKxW1dVe+z0iIl8B8oHvqeqxrm8uIouARQAjRozw7axMyGvxtPHJvqOs3l7K6h1lHDnRSHiYMCtnCF+6eATXTh5K1nkYX92Y/sSXANBd5+CuXRmeBp4Tkc049fybgFa3beA2YBRwHHhdRO5R1VeAF4Afu8f6MfAL4KunvJHqYmAxOFNC+nJSJjTVN7ey7rNKVm8v5YNd5ZxoaCEmMow5uWl877rxzJuQbneuGuPFlwBQAgz3ep1Nl2ocVa0G7gcQ526Sfe7jemCfqla4694ELgNeUdWy9v1F5DfAn87+NEyoOlrXzAc7y1i1vYwPd1fQ1NpGUmwk10zM4LrJGczJTWNQlDXGGtMdXwLABiBXREYBh3Aacb/ovYGIJAH1qtqM0+NnnapWi8hB4BIRicWpApqHU92DiGSq6hH3ELcD2/xxQmbgKzlWz+rtZazeUcon+47Sps7EIXfPGsF1kzOYlTOEiHDrL29MT3oMAKraKiKPAKtwuoG+pKrbReQhd/2LwETgZRHx4DQOP+Cu+1hElgMbgVacqqHF7qF/JiLTcKqA9gNf9+eJmYFDVfmsrNZpxN1RyrZD1QCMy4jnG3PHcv3koUzJSrShDIzpJdHuRoYKUnl5eZqfnx/oZJg+4GlTNh081tFd80BVPSIwfXgS108eynWThzIqNS7QyTSmXxCRAlXN67rc+r2ZoNHU6uGjoipW7yjl/R3lVNY2ERkuXDYmlUVzRnPtxAzSE2MCnUxjBgwLACagqhtbWFtYwartpazdVU5ds4f46Ajmjk/juslDmTs+jcSYyEAn05gByQKACYiSY/U8tXI7f/2sghaPkhofxfxpw7hu8lAuG5Ni88Ma0wcsAJg+t353Jd96bSOtHuW+y3K4fvJQpo9ItrlijeljFgBMn1FVXvjrHp5ZVcjY9Hj+75fzrCHXmACyAGD6RE1jC//0+hZWbS/jlqmZ/PTzU22aQWMCzH6B5rwrKq9h0X8VcKCqnv9180QemD3K+uwbEwQsAJjz6t1Pj/BPr29hUFQ4rzxwMZeOSQl0kowxLgsA5rxo9bTx81WF/N91e5k+IonnvzSDzME2+qYxwcQCgPG7qtomvvXaJj7aU8U9l4zgX2+ZZN06jQlCFgCMX20pPs7DrxRQWdfMzxdM5c684T3vZIwJCAsAxm9e++QgT761nbSEaN58+DKmZA0OdJKMMWdgAcCcs8YWD0++tZ2l+cVckZvKrxZOt4lXjOkHLACYc3LoeAMPv1LA1pITfPOqMXz32vF2R68x/YQFAHPW/lZUybde20RzaxuLvzyT6yYPDXSSjDG9YAHA9Jqq8uJf9/LzVbsYkxbPi1+eyZi0+EAnyxjTSxYATK/UNrXyz69v4d1tpdx8QSY/W2BDOhjTX9kv1/isqLyWr/9XPvur6vl/bprIg1fYkA7G9GcWAIxP3tt2hO8t20JMZDj/9cAsLhuTGugkGWPOkQWAPvTEik8p2H+MK8encdX4dPJykokMDwt0ss6o1dPGM6s/48W/7uHC4Um8eI8N6WDMQOFTABCRG4DngHDgt6r6dJf1yYCUDqYAABKPSURBVMBLwBigEfiqqm5z130HeBBQ4FPgflVtFJEhwFIgB9gP3KWqx/xwTkGp9EQjSz45yLCkQfz+b/tYvG4vCdERzM5N5aoJ6cwdlxZ0891W1Tbx6JJN/K2oii9ePIInb7UhHYwZSHoMACISDvwauBYoATaIyEpV3eG12RPAZlW9XUQmuNvPE5Es4FFgkqo2iMgyYCHwn8DjwAeq+rSIPO6+/r4fzy2ovLGxhDaFVx+8mJT4aP5WVMnawnLW7Krg3W2lAEzJSuTq8enMnZDOhdlJAe1Pv7XkOA/9lzOkw88WTOUuG9LBmAHHlyuAWUCRqu4FEJElwG2AdwCYBPw7gKruEpEcEcnweo9BItICxAKH3eW3AXPd538A1jJAA0Bbm7J0QzGXjk5hZIozA9b1k4dy/eShqCo7j9SwprCcNbvK+f/WFPGrvxQxJC6KK8elMXd8GleOSyMptu/urF264SD/+tZ20uKjeeOhy7gg24Z0MGYg8iUAZAHFXq9LgIu7bLMFuANYLyKzgJFAtqoWiMgzwEGgAVitqqvdfTJU9QiAqh4RkfTu3lxEFgGLAEaMGOHbWQWZf+yr4uDRer577bhT1okIk4YlMmlYIt+8aizH65tZt7uStbvKWftZBSs2HSJMYMaIZKeqaHwakzITz0vvm6ZWD0+t3M5rnxQze2wqv7p7OkNsSAdjBixfAkB3OY12ef008JyIbMap598EtLptA7cBo4DjwOsico+qvuJrAlV1MbAYIC8vr+v79gtLNxSTEBPBDVN6vlM2KTaK+RcOY/6Fw/C0KVtLjrNmVzlrCiv4+apCfr6qkIzEaK4an87c8enMzk0l3g/98A+7QzpsKTnBN+aO4XvX2ZAOxgx0vuQcJYB3BXA2ndU4AKhqNXA/gDhF033u43pgn6pWuOveBC4DXgHKRCTTLf1nAuXneC5B6UR9C+9uK2XhRcOJiexdA2p4mDB9RDLTRyTz3evGU17TyNrCCtYWlvPnrUdYsqGYyHBh1qghHQFhTFpcr68OPnKHdGhqbePFe2b6FKiMMf2fLwFgA5ArIqOAQziNuF/03kBEkoB6VW3G6fGzTlWrReQgcImIxOJUAc0D8t3dVgL34lw93Au85YfzCTpvbTlEc2ubXxpR0xNiuCtvOHflDafF00b+/mNOQ3JhOf/7zzv533/eyYghsVw1Po2rJqRzyeiUMwYdVWXxur389L1djE6L58V7ZjI23YZ0MCZUiGrPtSoichPwLE430JdU9Sci8hCAqr4oIpcCLwMenMbhB9q7dIrIj4AvAK04VUMPqmqTiKQAy4AROG0Ed6rq0TOlIy8vT/Pz88+0SdC56bkPEYE/P3rFeX2fkmP1rCmsYO2ucv62p5LGljZiIsO4bIzTzfSq8WlkJ8d2bF/b1Mq/LN/CO5+WctMFQ/nZggv9UpVkjAk+IlKgqnmnLPclAASL/hYAth06wS3/73p+fNtkvnxpTp+9b2OLh3/srWJtYQV/2VXOwaP1AOSmx3PVhHRmjEjimdWfsbeilsdvnMDXrhhtQzoYM4CdLgBYke88WrLhINERYcyfltWn7xsTGc5ct03gyVsnsbeyjjW7yllbWOHehKYMiYvilQcu5rKxNqSDMaHKAsB50tji4a3Nh7npgkwGD4oMWDpEhDFp8YxJi+fBK0ZT29TKxgPHmJCZQHpCcN15bIzpWxYAzpN3tx2hprE16O6gjY+OYM64tEAnwxgTBIJ7JLJ+bMknxYxMieWS0UMCnRRjjOmWBYDzYH9lHR/vO8pdecOtcdUYE7QsAJwHy/KLCRNYMDM70EkxxpjTsgDgZ62eNpYXlHD1hHQygmx4Z2OM8WYBwM/WFlZQXtMUdI2/xhjTlQUAP1uyoZjU+GiumtDt4KbGGBM0LAD4UXl1I2sKy1kwMzvop3o0xhjLpfzojY2H8LQpd+VZ468xJvhZAPATVWVZfjGzcoYwOs1G1DTGBD8LAH7yyb6j7Kus4wsXWeOvMaZ/sADgJ0vzi0mIjuCmCzIDnRRjjPGJBQA/qG5s4Z1PjzB/2jAGRfVu1i9jjAkUCwB+sHLzYRpb2qz6xxjTr1gA8IOlG4qZMDSBC7IGBzopxhjjMwsA52jH4Wo+PXSChRfZwG/GmP7FAsA5WpZfTFREGJ+b3rezfhljzLnyKQCIyA0iUigiRSLyeDfrk0VkhYhsFZFPRGSKu3y8iGz2elSLyGPuuqdE5JDXupv8e2rnX2OLhxWbDnH95KEkxUYFOjnGGNMrPc4IJiLhwK+Ba4ESYIOIrFTVHV6bPQFsVtXbRWSCu/08VS0Epnkd5xCwwmu//1DVZ/xzKn1v1fZSTjS0sNAaf40x/ZAvVwCzgCJV3auqzcAS4LYu20wCPgBQ1V1AjohkdNlmHrBHVQ+cY5qDxtINxQwfMohLR6cEOinGGNNrvgSALKDY63WJu8zbFuAOABGZBYwEug6IsxB4rcuyR9xqo5dEJLm7NxeRRSKSLyL5FRUVPiS3bxysquejPVXcNXM4YWHW+GuM6X98CQDd5W7a5fXTQLKIbAa+BWwCWjsOIBIFzAde99rnBWAMThXREeAX3b25qi5W1TxVzUtLC57JzF8vcGf9soHfjDH9VI9tADglfu9K7mzgsPcGqloN3A8gTl/Ife6j3Y3ARlUt89qn47mI/Ab4U28THyieNuX1/BLmjEsjc/CgQCfHGGPOii9XABuAXBEZ5ZbkFwIrvTcQkSR3HcCDwDo3KLS7my7VPyLiPWjO7cC23iY+UNZ9VkFpdaM1/hpj+rUerwBUtVVEHgFWAeHAS6q6XUQecte/CEwEXhYRD7ADeKB9fxGJxelB9PUuh/6ZiEzDqU7a3836oLV0QzEpcVFcPaFrO7cxxvQfvlQBoarvAO90Wfai1/O/A7mn2bceOKWbjKp+uVcpDRIVNU38z84y7r88h6gIu4/OGNN/WQ7WSys2ldDapjbwmzGm37MA0AuqypINxcwcmczY9IRAJ8cYY86JBYBeKDhwjL0VNuuXMWZgsADQC0s3FBMXFc7NNuuXMWYAsADgo5rGFv609Qi3XjiMuGif2s6NMSaoWQDw0Z+2HqGhxWPVP8aYAcMCgI+WbChmXEY804YnBTopxhjjFxYAfFBYWsOW4uPclWezfhljBg4LAD5YuqGYyHDhjhk28JsxZuCwANCDplYPb24q4bpJQxkSZ7N+GWMGDgsAPXh/RxnH61us8dcYM+BYAOjB0g3FZCUNYvbY1EAnxRhj/MoCwBmUHKtnfVElC2Zm26xfxpgBxwLAGbyeXwLAnTbrlzFmALIAcBrOrF/FzB6bSnZybKCTY4wxfmcB4DTWF1Vy+EQjCy8aEeikGGPMeWEB4DSWbSgmOTaSayalBzopxhhzXlgA6EZVbROrd5Ry+/RsoiPCA50cY4w5LywAdGPFpkO0eGzWL2PMwOZTABCRG0SkUESKROTxbtYni8gKEdkqIp+IyBR3+XgR2ez1qBaRx9x1Q0TkfRHZ7f5N9u+pnR1VZVl+MdOGJzF+qM36ZYwZuHoMACISDvwauBGYBNwtIpO6bPYEsFlVpwJfAZ4DUNVCVZ2mqtOAmUA9sMLd53HgA1XNBT5wXwfcpuLjfFZWa6V/Y8yA58sVwCygSFX3qmozsAS4rcs2k3AycVR1F5AjIhldtpkH7FHVA+7r24A/uM//AHzuLNLvd8s2FBMbFc6tFw4LdFKMMea88iUAZAHFXq9L3GXetgB3AIjILGAk0PXuqYXAa16vM1T1CID7t9vuNiKySETyRSS/oqLCh+SevbqmVt7ecpibL8gk3mb9MsYMcL4EgO7GQNAur58GkkVkM/AtYBPQ2nEAkShgPvB6bxOoqotVNU9V89LS0nq7e6/8eesR6po9LJxl1T/GmIHPl2JuCeCdI2YDh703UNVq4H4AcWZM2ec+2t0IbFTVMq9lZSKSqapHRCQTKD+L9PvV0vxixqTFMWNEULRHG2PMeeXLFcAGIFdERrkl+YXASu8NRCTJXQfwILDODQrt7ubk6h/cY9zrPr8XeKu3ifenovIaCg4c4wsX2axfxpjQ0OMVgKq2isgjwCogHHhJVbeLyEPu+heBicDLIuIBdgAPtO8vIrHAtcDXuxz6aWCZiDwAHATu9MP5nLWlG4qJCLNZv4wxocOnlk5VfQd4p8uyF72e/x3IPc2+9UBKN8urcHoGBVxzaxtvbDzENRMzSI2PDnRyjDGmT9idwMAHO8s4Wtdsff+NMSHFAgBO4+/QxBjmjDu/vYyMMSaYhHwAOHy8gb9+VsGdedmE26xfxpgQEvIBYHlBCapwV55V/xhjQktIB4C2Nmfgt8vHpjB8iM36ZYwJLSEdAD7aU0XJsQYr/RtjQlJIB4Cl+cUMHhTJ9ZOHBjopxhjT50I2AByra2bVtlJun55FTKTN+mWMCT0hGwD+e/Mhmj1tVv1jjAlZIRkAVJWlG4qZmj2YScMSA50cY4wJiJAMAFtLTrCrtMZK/8aYkBaSAWBpfjExkWHMn2azfhljQlfIBYD65lZWbj7MTRdkkhgTGejkGGNMwIRcAHjn01Jqm1r5glX/GGNCXMgFgGUbihmVGsesUUMCnRRjjAmokAoAeypq+WT/Ue7Ks1m/jDEmpALAsvxiwsOEz8/MCnRSjDEm4EImALR42nij4BBXT0gnPSEm0MkxxpiAC5kA8Jdd5VTWNlnjrzHGuEImACzbUEx6QjRzx9usX8YYAz4GABG5QUQKRaRIRB7vZn2yiKwQka0i8omITPFalyQiy0Vkl4jsFJFL3eVPicghEdnsPm7y32mdrPREI2sKy1kwM5uI8JCJecYYc0YRPW0gIuHAr4FrgRJgg4isVNUdXps9AWxW1dtFZIK7/Tx33XPAe6q6QESiAO+ZV/5DVZ/xx4mcyRsbS2izWb+MMeYkvhSHZwFFqrpXVZuBJcBtXbaZBHwAoKq7gBwRyRCRRGAO8Dt3XbOqHvdb6n2UlhDNXXnZ5KTG9fVbG2NM0PIlAGQBxV6vS9xl3rYAdwCIyCxgJJANjAYqgN+LyCYR+a2IeOfCj7jVRi+JSHJ3by4ii0QkX0TyKyoqfDurLu7KG87PFlx4VvsaY8xA5UsA6O6OKe3y+mkgWUQ2A98CNgGtOFVMM4AXVHU6UAe0tyG8AIwBpgFHgF909+aqulhV81Q1Ly3NGnCNMcZfemwDwCnxe1eeZwOHvTdQ1WrgfgBxbrHd5z5igRJV/djddDluAFDVsvb9ReQ3wJ/O7hSMMcacDV+uADYAuSIyym3EXQis9N7A7ekT5b58EFinqtWqWgoUi8h4d908YIe7T6bXIW4Htp3DeRhjjOmlHq8AVLVVRB4BVgHhwEuqul1EHnLXvwhMBF4WEQ9OBv+A1yG+BbzqBoi9uFcKwM9EZBpOddJ+4Ov+OSVjjDG+ENWu1fnBKy8vT/Pz8wOdDGOM6VdEpEBV87out7uijDEmRFkAMMaYEGUBwBhjQlS/agMQkQrgwFnungpU+jE5/Z19Hp3ssziZfR4nGwifx0hVPeVGqn4VAM6FiOR31wgSquzz6GSfxcns8zjZQP48rArIGGNClAUAY4wJUaEUABYHOgFBxj6PTvZZnMw+j5MN2M8jZNoAjDHGnCyUrgCMMcZ4sQBgjDEhKiQCQE9zGocKERkuImvcuZm3i8i3A52mYCAi4e6ERSE/JPnp5vAORSLyHfd3sk1EXhORmECnyd8GfADwmtP4RpypK+8WkUmBTVXAtALfU9WJwCXAN0P4s/D2bWBnoBMRJNrn8J4AXEiIfi4ikgU8CuSp6hSckZAXBjZV/jfgAwC+zWkcElT1iKpudJ/X4Py4u07vGVJEJBu4GfhtoNMSaMEyh3cQiQAGiUgEzuRWh3vYvt8JhQDgy5zGIUdEcoDpwMdn3nLAexb4F6At0AkJAj3N4R0yVPUQ8AxwEGfK2hOqujqwqfK/UAgAvsxpHFJEJB54A3jMnc4zJInILUC5qhYEOi1B4kxzeIcUEUnGqSkYBQwD4kTknsCmyv9CIQD0OKdxKBGRSJzM/1VVfTPQ6Qmwy4H5IrIfp2rwahF5JbBJCqgSTp3De0YA0xNI1wD7VLVCVVuAN4HLApwmvwuFANDjnMahQkQEp353p6r+MtDpCTRV/YGqZqtqDs734i+qOuBKeb460xzeIeggcImIxLq/m3kMwAbxHucE7u9ON6dxgJMVKJcDXwY+FZHN7rInVPWdAKbJBJfTzeEdUlT1YxFZDmzE6T23iQE4JIQNBWGMMSEqFKqAjDHGdMMCgDHGhCgLAMYYE6IsABhjTIiyAGCMMSHKAoAxxoQoCwDGGBOi/n+be0TPs0yO1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련 결과 시각화\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.192509651184082\n"
     ]
    }
   ],
   "source": [
    "#test_set으로 예측\n",
    "import time\n",
    "start = time.time()\n",
    "value = model.predict(test_set)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0157 - acc: 0.9952\n",
      "acc: 99.52%\n"
     ]
    }
   ],
   "source": [
    "#test_set으로 모델 평가\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate(test_set)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetinaFace모델과 같이 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import RetinaFaceModel\n",
    "from modules.utils import (set_memory_growth, load_yaml, draw_bbox_landm,\n",
    "                           pad_input_image, recover_pad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.functional.Functional object at 0x000001750870DA30> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x000001750560C520>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.FPN object at 0x000001750870D850> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x000001750560C790>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.SSH object at 0x0000017504C54B20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x00000175056320A0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.SSH object at 0x0000017504C54C40> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505633CD0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.SSH object at 0x0000017504DCF880> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505633C70>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.ClassHead object at 0x000001750545EE20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505622EE0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.ClassHead object at 0x000001750545A460> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505633910>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.ClassHead object at 0x0000017505448E80> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x000001750560EB80>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.BboxHead object at 0x0000017504E3E6A0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505632370>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.BboxHead object at 0x0000017504C415B0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505622C10>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.BboxHead object at 0x000001750543A7C0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505627E80>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.LandmarkHead object at 0x000001750543FAC0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x00000175056329D0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.LandmarkHead object at 0x0000017505420220> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000017505723640>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<modules.models.LandmarkHead object at 0x0000017505402310> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x000001750560E970>).\n",
      "[*] load ckpt from ./checkpoints/retinaface_mbv2\\ckpt-81.\n"
     ]
    }
   ],
   "source": [
    "cfg = load_yaml('./configs/retinaface_mbv2.yaml')\n",
    "\n",
    "# define network\n",
    "model1 = RetinaFaceModel(cfg, training=False, iou_th=0.4,\n",
    "                            score_th=0.5)\n",
    "\n",
    "# load checkpoint\n",
    "checkpoint_dir = './checkpoints/' + cfg['sub_name']\n",
    "checkpoint = tf.train.Checkpoint(model=model1)\n",
    "if tf.train.latest_checkpoint(checkpoint_dir):\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    print(\"[*] load ckpt from {}.\".format(\n",
    "        tf.train.latest_checkpoint(checkpoint_dir)))\n",
    "else:\n",
    "    print(\"[*] Cannot find ckpt from {}.\".format(checkpoint_dir))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict={0:'without_mask',1:'with_mask'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "#webcam read\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    if frame is None:\n",
    "        print(\"no cam input\")\n",
    "          \n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    img = np.float32(frame.copy())\n",
    "    img = cv2.resize(img, (0, 0), fx=0.2, fy=0.2, interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # pad input image to avoid unmatched shape problem\n",
    "    img, pad_params = pad_input_image(img, 32)\n",
    "\n",
    "    # run model\n",
    "    outputs = model1(img[np.newaxis, ...]).numpy()\n",
    "\n",
    "    # recover padding effect\n",
    "    outputs = recover_pad_output(outputs, pad_params)\n",
    "    cv2.putText(frame, str(len(outputs)), (100, 50),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2)\n",
    "    if len(outputs) == 0 or len(outputs) >= 2:\n",
    "        pass\n",
    "    elif len(outputs) == 1:\n",
    "        # 얼굴 박스만 따서 이미지 자르기\n",
    "        bounding_box = outputs[0,:4]\n",
    "        x1, y1, x2, y2 = bounding_box[0] * frame_width, bounding_box[1] * frame_height, \\\n",
    "                         bounding_box[2] * frame_width, bounding_box[3] * frame_height\n",
    "        \n",
    "        bb_width = x2 - x1\n",
    "        bb_height = y2 - y1\n",
    "    \n",
    "        if bb_height < 112:\n",
    "            cv2.putText(frame, \"Please Come Closer\", (200, 50),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2)\n",
    "        elif bb_height > 112:\n",
    "            # 얼굴이 세로가 더 길기때문에 가로길이를 좀 더 늘려서 세로 비율 동일하게 얼굴영역 산출\n",
    "            pad = (bb_height - bb_width) / 2\n",
    "            x1 -= (10+pad)\n",
    "            x2 += (10+pad)\n",
    "            y1 -= 10\n",
    "            y2 += 10\n",
    "            # 얼굴영역 자르기\n",
    "            if x1 < 0 or x2 > frame_width:\n",
    "                pass\n",
    "            else:\n",
    "                face_img = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                # 112x112 리사이징\n",
    "                resized=cv2.resize(face_img,(112,112))\n",
    "                resized=cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "                #plt.imshow(resized)\n",
    "                #plt.show()\n",
    "                normalized=resized/255.0\n",
    "                reshaped=np.reshape(normalized,(1,112,112,3))\n",
    "                reshaped = np.vstack([reshaped])\n",
    "                result=model.predict(reshaped)\n",
    "                \n",
    "                label=np.argmax(result,axis=1)[0]\n",
    "                \n",
    "                if result[0][1] == 1.0:\n",
    "                    cv2.rectangle(frame,(int(x1),int(y1)),(int(x2),int(y2)),color_dict[1],2)\n",
    "                    cv2.rectangle(frame,(int(x1),int(y1-40)),(int(x2),int(y1)),color_dict[1],-1)\n",
    "                    cv2.putText(frame, labels_dict[1], (int(x1), int(y1-10)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "                    cv2.putText(frame, str(result[0][-5:]), (int(x1), int(y1-50)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame,(int(x1),int(y1)),(int(x2),int(y2)),color_dict[0],2)\n",
    "                    cv2.rectangle(frame,(int(x1),int(y1-40)),(int(x2),int(y1)),color_dict[0],-1)\n",
    "                    cv2.putText(frame, labels_dict[0], (int(x1), int(y1-10)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "                    cv2.putText(frame, str(result[0][-5:]), (int(x1), int(y1-50)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    else:\n",
    "        pass\n",
    "              \n",
    "    # calculate fps\n",
    "    fps_str = \"FPS: %.2f\" % (1 / (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    cv2.putText(frame, fps_str, (25, 25), cv2.FONT_HERSHEY_DUPLEX, 0.75, (0, 255, 0), 1)\n",
    "    \n",
    "    # show frame           \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Stop video\n",
    "cam.release()\n",
    "# Close all started windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop video\n",
    "cam.release()\n",
    "# Close all started windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
